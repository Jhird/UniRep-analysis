{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from subprocess import call\n",
    "\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from scipy.stats import ttest_1samp\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "from scipy.stats import spearmanr, pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import common_v2.validation_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_v2.validation_tools import reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filetype = 'loaded_full_dataset'\n",
    "processed_all_rds = pd.read_pickle(f\"../../../data/pieces_new/rocklin_all_rds__all_rds_stability.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../../data/\"\n",
    "datasets = ['rd1','rd2', 'rd3', 'rd4']\n",
    "\n",
    "dfs = {lib:pd.read_table(path+lib+\"_stability_scores\") for lib in datasets}\n",
    "all_rds = pd.concat(list(dfs.values())) # except ssm2\n",
    "\n",
    "#all_rds = all_rds.drop_duplicates(subset='name', keep=False) #dropping duplicate records that have the same name. \n",
    "# This step is necessary for the correct join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56083, 26)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_all_rds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56183, 18)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56140,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rds.sequence.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = processed_all_rds[(processed_all_rds.is_train == True) & (processed_all_rds.is_test == False) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44942, 26)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44942,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sequence.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44942,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences_with_annotations = np.intersect1d(train.sequence, all_rds.sequence)\n",
    "train_sequences_with_annotations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44942, 26)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = all_rds.set_index('sequence').loc[train.sequence,['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = train_names[~train_names.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.set_index('sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train_names.index,'fold_topology'] = train_names.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    44942\n",
       "Name: fold_topology, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.fold_topology.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fold_topology = train.fold_topology.map(lambda x: x.split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EEHEE                    12942\n",
       "HEEH                     12376\n",
       "EHEE                      8847\n",
       "HHH                       6630\n",
       "chymo                     1184\n",
       "tryp                       800\n",
       "arc                         54\n",
       "pin1                        51\n",
       "p53tetS-gabeshortened       31\n",
       "BBL                         25\n",
       "GCN4                        20\n",
       "villin                      12\n",
       "GCN4-VNVV                   11\n",
       "hYAP65                      11\n",
       "PFRD-XC4                     7\n",
       "Name: fold_topology, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.fold_topology.value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "topologies = [\"EEHEE\", \"HEEH\", \"EHEE\", \"HHH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.fold_topology.isin(topologies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40795, 26)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEHEE\n",
      "trained\n",
      "HEEH\n",
      "trained\n",
      "EHEE\n",
      "trained\n",
      "HHH\n",
      "trained\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "\n",
    "for top in topologies:\n",
    "    train_top = train[train.fold_topology == top]\n",
    "    print(top)\n",
    "    \n",
    "    model = LassoLarsCV(\n",
    "                        fit_intercept = True,\n",
    "                        normalize = True,\n",
    "                        n_jobs=-1,\n",
    "                        max_n_alphas=6000,\n",
    "                        cv=10\n",
    "                    )\n",
    "    \n",
    "    model.fit(np.asarray(train_top['all_1900'].values.tolist()), train_top['phenotype'].values.astype('float'))\n",
    "    \n",
    "    models[top] = model\n",
    "    print(\"trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EEHEE': LassoLarsCV(copy_X=True, cv=10, eps=2.2204460492503131e-16,\n",
       "       fit_intercept=True, max_iter=500, max_n_alphas=6000, n_jobs=-1,\n",
       "       normalize=True, positive=False, precompute='auto', verbose=False),\n",
       " 'HEEH': LassoLarsCV(copy_X=True, cv=10, eps=2.2204460492503131e-16,\n",
       "       fit_intercept=True, max_iter=500, max_n_alphas=6000, n_jobs=-1,\n",
       "       normalize=True, positive=False, precompute='auto', verbose=False),\n",
       " 'EHEE': LassoLarsCV(copy_X=True, cv=10, eps=2.2204460492503131e-16,\n",
       "       fit_intercept=True, max_iter=500, max_n_alphas=6000, n_jobs=-1,\n",
       "       normalize=True, positive=False, precompute='auto', verbose=False),\n",
       " 'HHH': LassoLarsCV(copy_X=True, cv=10, eps=2.2204460492503131e-16,\n",
       "       fit_intercept=True, max_iter=500, max_n_alphas=6000, n_jobs=-1,\n",
       "       normalize=True, positive=False, precompute='auto', verbose=False)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_type = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/grig_alldatasets_run/lib/python3.6/site-packages/ipykernel/__main__.py:24: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"../../../data/\"\n",
    "datasets = ['rd1','rd2', 'rd3', 'rd4']\n",
    "\n",
    "dfs = {lib:pd.read_table(path+lib+\"_stability_scores\") for lib in datasets}\n",
    "all_rds = pd.concat(list(dfs.values())) # except ssm2\n",
    "\n",
    "all_rds = all_rds.drop_duplicates(subset='name', keep=False) #dropping duplicate records that have the same name. \n",
    "# This step is necessary for the correct join\n",
    "\n",
    "validate = pd.read_pickle(f\"{path}for_rosetta_comparison_rocklin_all_rds_{run_type}_sequences_and_truey.pdpkl\")\n",
    "\n",
    "rock_data = [pd.read_csv(f\"{path}rd{i}_relax_scored_filtered_betanov15.sc\", sep='\\t') for i in [1,2,3,4]]\n",
    "\n",
    "rock_data = pd.concat([rock_data[x][['sequence', 'description', 'total_score', 'exposed_hydrophobics', \n",
    "                                    'buried_np', \n",
    "                                    'one_core_each', \n",
    "                                    'two_core_each',\n",
    "                                    'percent_core_SCN',\n",
    "                                    'buried_minus_exposed', \n",
    "                                    'buried_over_exposed', \n",
    "                                    'contact_all']] for x in [0,1,2,3]]).set_index('sequence')\n",
    "\n",
    "validate_meta = all_rds.set_index('sequence').loc[validate.rep].reset_index().copy()\n",
    "\n",
    "validate_meta.loc[:,'predicted_unirep_fusion_stability'] = np.load(f\"{path}rocklin_all_rds__all_rds_stability__all_1900__{run_type}__predictions.npy\")\n",
    "\n",
    "validate_meta.loc[:,'target'] =validate.target\n",
    "\n",
    "ids_in_common = np.intersect1d(rock_data.description.values,validate_meta.name.dropna().values)\n",
    "\n",
    "rock_data = rock_data.reset_index().set_index('description')\n",
    "\n",
    "common_df = validate_meta.set_index('name').loc[ids_in_common]\n",
    "\n",
    "common_df = common_df.join(rock_data, lsuffix='val', rsuffix='ros_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = processed_all_rds[(processed_all_rds.is_train == False) & (processed_all_rds.is_test == True) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.set_index('sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5570, 25)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1432, 29)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_df.loc[:,\"all_1900\"] = test.loc[common_df.sequenceval, 'all_1900'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_df = common_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for top in topologies:\n",
    "    sliced = common_df[common_df.name.map(lambda x: x.split(\"_\")[0]) == top]\n",
    "    \n",
    "    results[top] = {\n",
    "        'UniRep_all_topo':spearmanr(sliced['predicted_unirep_fusion_stability'],sliced['target'])[0],\n",
    "        'UniRep_single_topo':spearmanr(models[top].predict(np.asarray(sliced['all_1900'].values.tolist())),sliced['target'])[0],\n",
    "        'buried_NPSA':spearmanr(sliced['buried_np'],sliced['target'])[0],\n",
    "        'exposed_NPSA':spearmanr(sliced['exposed_hydrophobics'],sliced['target'])[0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for top in topologies:\n",
    "    sliced = common_df[common_df.name.map(lambda x: x.split(\"_\")[0]) == top]\n",
    "    \n",
    "    results[top]['Rosetta'] = spearmanr(-sliced['total_score'],sliced['target'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EEHEE</th>\n",
       "      <th>HEEH</th>\n",
       "      <th>EHEE</th>\n",
       "      <th>HHH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UniRep_single_topo</th>\n",
       "      <td>0.698290</td>\n",
       "      <td>0.434377</td>\n",
       "      <td>0.641517</td>\n",
       "      <td>0.719980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rosetta</th>\n",
       "      <td>0.597387</td>\n",
       "      <td>0.057320</td>\n",
       "      <td>0.472592</td>\n",
       "      <td>0.596452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buried_NPSA</th>\n",
       "      <td>0.544916</td>\n",
       "      <td>0.044305</td>\n",
       "      <td>0.509138</td>\n",
       "      <td>0.632409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exposed_NPSA</th>\n",
       "      <td>0.549854</td>\n",
       "      <td>0.089763</td>\n",
       "      <td>0.451996</td>\n",
       "      <td>0.060656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       EEHEE      HEEH      EHEE       HHH\n",
       "UniRep_single_topo  0.698290  0.434377  0.641517  0.719980\n",
       "Rosetta             0.597387  0.057320  0.472592  0.596452\n",
       "buried_NPSA         0.544916  0.044305  0.509138  0.632409\n",
       "exposed_NPSA        0.549854  0.089763  0.451996  0.060656"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).loc[['UniRep_single_topo','Rosetta', 'buried_NPSA', 'exposed_NPSA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:grig_alldatasets_run]",
   "language": "python",
   "name": "conda-env-grig_alldatasets_run-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
